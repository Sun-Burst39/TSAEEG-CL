{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers            \n",
    "from tensorflow.keras.layers import AveragePooling2D,Dense,Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import layers,optimizers,losses\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "from keras.layers import Activation\n",
    "from tensorflow.keras.layers import Input,Flatten,LSTM\n",
    "from tensorflow.keras.layers import Embedding, Layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置GPU使用方式\n",
    "# 获取GPU列表\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # 设置GPU为增长式占用\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu,True)\n",
    "    except RuntimeError as e:\n",
    "        #打印异常\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsz = 16\n",
    "#加载数据\n",
    "#1）一次性读入全部数据到内存\n",
    "data_all=np.load('D:/An/脑电/实验数据/epoch/训练前后分类/xunlian.npy')\n",
    "#data_alln=np.expand_dims(x_train,axis=3)\n",
    "label_all=np.concatenate((np.zeros((4797,1),dtype=int),np.ones((4802,1),dtype=int)),axis=0)\n",
    "label_all=np.eye(2)[label_all]\n",
    "label_all=np.squeeze(label_all)\n",
    "n=len(data_all)\n",
    "A = np.linspace(0,n-1,n,dtype=int)\n",
    "random.shuffle(A)\n",
    "data_all=data_all[A]\n",
    "label_all=label_all[A]\n",
    "#print(data_all,label_all.shape)\n",
    "#print(n)\n",
    "kfold=KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "# 创建所有要保存结果的空列表\n",
    "historys,test_pred,test_real,accuracy,precision,recall,f1score=list(),list(),list(),list(),list(),list(),list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeEmbeddingLayer(Layer):\n",
    "    def __init__(self, num_channels, sequence_length, output_dim, **kwargs):\n",
    "        super(TimeEmbeddingLayer, self).__init__(**kwargs)\n",
    "        self.num_channels = num_channels\n",
    "        self.sequence_length = sequence_length\n",
    "        self.output_dim = output_dim\n",
    "        self.time_embedding_layer = Embedding(input_dim=sequence_length, output_dim=output_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        position = tf.range(self.sequence_length)\n",
    "        embed = self.time_embedding_layer(position)\n",
    "        embed = tf.reshape(embed, (1, 1, self.sequence_length, self.output_dim))\n",
    "        return inputs + embed\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(TimeEmbeddingLayer, self).get_config()\n",
    "        config.update({\n",
    "            \"num_channels\": self.num_channels,\n",
    "            \"sequence_length\": self.sequence_length,\n",
    "            \"output_dim\": self.output_dim\n",
    "        })\n",
    "        return config\n",
    "\n",
    "class ChannelEmbeddingLayer(Layer):\n",
    "    def __init__(self, num_channels, sequence_length, output_dim, **kwargs):\n",
    "        super(ChannelEmbeddingLayer, self).__init__(**kwargs)\n",
    "        self.num_channels = num_channels\n",
    "        self.sequence_length = sequence_length\n",
    "        self.output_dim = output_dim\n",
    "        self.channel_embedding_layer = Embedding(input_dim=num_channels, output_dim=output_dim)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        position = tf.range(self.num_channels)\n",
    "        embed = self.channel_embedding_layer(position)\n",
    "        embed = tf.reshape(embed, (1, self.num_channels, 1, self.output_dim))\n",
    "        return inputs + embed\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(ChannelEmbeddingLayer, self).get_config()\n",
    "        config.update({\n",
    "            \"num_channels\": self.num_channels,\n",
    "            \"sequence_length\": self.sequence_length,\n",
    "            \"output_dim\": self.output_dim\n",
    "        })\n",
    "        return config\n",
    "\n",
    "def mymodel1():\n",
    "    input = layers.Input(shape=(30,36,40))\n",
    "    x=TimeEmbeddingLayer(num_channels=30, sequence_length=36, output_dim=40)(input)\n",
    "    x=layers.Conv2D(40,kernel_size=(30,1),strides=(1,1))(x)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    x=layers.ReLU()(x)\n",
    "    x=layers.Reshape((x.shape[2],x.shape[3]))(x)\n",
    "    attn_input=x\n",
    "    x=layers.MultiHeadAttention(num_heads=8,key_dim=40)(x,x)\n",
    "    x=layers.Add()([x,attn_input])\n",
    "    x=layers.LSTM(units=100, return_sequences=True)(x)\n",
    "    model = Model(inputs=input, outputs=x)\n",
    "    return model\n",
    "\n",
    "def mymodel2():\n",
    "    input = layers.Input(shape=(30,36,40))\n",
    "    x=ChannelEmbeddingLayer(num_channels=30, sequence_length=36, output_dim=40)(input)\n",
    "    x=layers.Conv2D(40, kernel_size=(1,36), strides=(1, 1))(x)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    x=layers.ReLU()(x)\n",
    "    x=layers.Reshape((x.shape[1],x.shape[3]))(x)\n",
    "    attn_input=x\n",
    "    x=layers.MultiHeadAttention(num_heads=8,key_dim=40)(x,x)\n",
    "    x=layers.Add()([x,attn_input])\n",
    "    x=layers.LSTM(units=100, return_sequences=True)(x)\n",
    "    model = Model(inputs=input, outputs=x)\n",
    "    return model\n",
    "\n",
    "def siamese_network(inp_shape=(30,200,1)):\n",
    "    inp=Input(shape=inp_shape)\n",
    "    x=layers.Conv2D(40,kernel_size=(1,15),strides=(1,1),\n",
    "                      name='conv_1d_temporal',\n",
    "                      kernel_regularizer=regularizers.l2(0.01),\n",
    "                      bias_regularizer=regularizers.l2(0.01)\n",
    "                      )(inp)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    x=layers.ReLU()(x)\n",
    "    x=AveragePooling2D(pool_size=(1,10),strides=(1,5))(x)\n",
    "    out1=mymodel1()(x)\n",
    "    out2=mymodel2()(x)\n",
    "    merged=tf.keras.layers.concatenate([out1,out2],axis=1)\n",
    "    x=layers.Flatten()(merged)\n",
    "    x=layers.Dense(100, activation=\"relu\")(x)\n",
    "    x=layers.Dropout(0.5)(x)\n",
    "    x=layers.Dense(50, activation=\"relu\")(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    return model\n",
    "\n",
    "def mymodel(nb_classes=2, dropoutRate=0.5):\n",
    "    inp_shape=(2,30,200,1)\n",
    "    inp = layers.Input(shape=inp_shape)\n",
    "    split1,split2=tf.unstack(inp,axis=1)\n",
    "    siamese=siamese_network(inp_shape=(30, 200, 1))\n",
    "    feature1=siamese(split1)\n",
    "    feature2=siamese(split2)\n",
    "    x=layers.Add()([feature1, feature2])\n",
    "    x=layers.Dense(100, activation='relu')(x)\n",
    "    x=layers.Dropout(dropoutRate)(x)\n",
    "    x=layers.Dense(50, activation='relu')(x)\n",
    "    output=layers.Dense(nb_classes, activation='softmax')(x)\n",
    "    model=keras.models.Model(inputs=inp,outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold hao: 1\n",
      "(6911, 2, 30, 200)\n",
      "(6911, 2)\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 2, 30, 200,  0           []                               \n",
      "                                 1)]                                                              \n",
      "                                                                                                  \n",
      " tf.unstack (TFOpLambda)        [(None, 30, 200, 1)  0           ['input_1[0][0]']                \n",
      "                                , (None, 30, 200, 1                                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " model_2 (Functional)           (None, 50)           991790      ['tf.unstack[0][0]',             \n",
      "                                                                  'tf.unstack[0][1]']             \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 50)           0           ['model_2[0][0]',                \n",
      "                                                                  'model_2[1][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 100)          5100        ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 100)          0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 50)           5050        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 2)            102         ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,002,042\n",
      "Trainable params: 1,001,802\n",
      "Non-trainable params: 240\n",
      "__________________________________________________________________________________________________\n",
      "开始训练!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "432/432 [==============================] - 26s 32ms/step - loss: 0.2125 - accuracy: 0.6895 - val_loss: 0.1112 - val_accuracy: 0.8698 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.1095 - accuracy: 0.8780 - val_loss: 0.1588 - val_accuracy: 0.8021 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0769 - accuracy: 0.9197 - val_loss: 0.0602 - val_accuracy: 0.9427 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0629 - accuracy: 0.9400 - val_loss: 0.0684 - val_accuracy: 0.9265 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "432/432 [==============================] - 12s 27ms/step - loss: 0.0541 - accuracy: 0.9499 - val_loss: 0.0501 - val_accuracy: 0.9560 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0470 - accuracy: 0.9604 - val_loss: 0.0486 - val_accuracy: 0.9583 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0430 - accuracy: 0.9663 - val_loss: 0.0482 - val_accuracy: 0.9583 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0425 - accuracy: 0.9644 - val_loss: 0.0560 - val_accuracy: 0.9514 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0346 - accuracy: 0.9751 - val_loss: 0.0412 - val_accuracy: 0.9647 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0361 - accuracy: 0.9744 - val_loss: 0.1071 - val_accuracy: 0.8877 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0313 - accuracy: 0.9767 - val_loss: 0.0285 - val_accuracy: 0.9832 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0328 - accuracy: 0.9753 - val_loss: 0.0281 - val_accuracy: 0.9832 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0283 - accuracy: 0.9823 - val_loss: 0.0384 - val_accuracy: 0.9693 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0278 - accuracy: 0.9813 - val_loss: 0.0339 - val_accuracy: 0.9751 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "432/432 [==============================] - 11s 27ms/step - loss: 0.0279 - accuracy: 0.9816 - val_loss: 0.0470 - val_accuracy: 0.9589 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0259 - accuracy: 0.9841 - val_loss: 0.0316 - val_accuracy: 0.9780 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0254 - accuracy: 0.9823 - val_loss: 0.0256 - val_accuracy: 0.9832 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0214 - accuracy: 0.9890 - val_loss: 0.0397 - val_accuracy: 0.9676 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0227 - accuracy: 0.9873 - val_loss: 0.0234 - val_accuracy: 0.9867 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0233 - accuracy: 0.9860 - val_loss: 0.0321 - val_accuracy: 0.9734 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0210 - accuracy: 0.9884 - val_loss: 0.0247 - val_accuracy: 0.9844 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0223 - accuracy: 0.9873 - val_loss: 0.0473 - val_accuracy: 0.9572 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0211 - accuracy: 0.9878 - val_loss: 0.0249 - val_accuracy: 0.9832 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0193 - accuracy: 0.9902 - val_loss: 0.0275 - val_accuracy: 0.9792 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0150 - accuracy: 0.9954 - val_loss: 0.0202 - val_accuracy: 0.9884 - lr: 1.0000e-05\n",
      "Epoch 26/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0141 - accuracy: 0.9962 - val_loss: 0.0205 - val_accuracy: 0.9884 - lr: 1.0000e-05\n",
      "Epoch 27/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0146 - accuracy: 0.9952 - val_loss: 0.0202 - val_accuracy: 0.9878 - lr: 1.0000e-05\n",
      "Epoch 28/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0136 - accuracy: 0.9971 - val_loss: 0.0199 - val_accuracy: 0.9902 - lr: 1.0000e-05\n",
      "Epoch 29/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0140 - accuracy: 0.9962 - val_loss: 0.0205 - val_accuracy: 0.9896 - lr: 1.0000e-05\n",
      "Epoch 30/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0131 - accuracy: 0.9975 - val_loss: 0.0198 - val_accuracy: 0.9896 - lr: 1.0000e-05\n",
      "Epoch 31/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0126 - accuracy: 0.9978 - val_loss: 0.0198 - val_accuracy: 0.9890 - lr: 1.0000e-05\n",
      "Epoch 32/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0131 - accuracy: 0.9973 - val_loss: 0.0195 - val_accuracy: 0.9902 - lr: 1.0000e-05\n",
      "Epoch 33/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0122 - accuracy: 0.9990 - val_loss: 0.0195 - val_accuracy: 0.9902 - lr: 1.0000e-05\n",
      "Epoch 34/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0133 - accuracy: 0.9974 - val_loss: 0.0194 - val_accuracy: 0.9907 - lr: 1.0000e-05\n",
      "Epoch 35/100\n",
      "432/432 [==============================] - 12s 27ms/step - loss: 0.0121 - accuracy: 0.9988 - val_loss: 0.0196 - val_accuracy: 0.9890 - lr: 1.0000e-05\n",
      "(960, 2)\n",
      "(960, 2)\n",
      "$$ 测试集准确率为 accuracy:0.990625\n",
      "$$ 测试集精确率为 precision:0.9906051017617876\n",
      "$$ 测试集召回率为 recall:0.9906626035318018\n",
      "$$ 测试集f1评分为 f1_score:0.9906241759529646\n",
      "fold hao: 2\n",
      "(6911, 2, 30, 200)\n",
      "(6911, 2)\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 2, 30, 200,  0           []                               \n",
      "                                 1)]                                                              \n",
      "                                                                                                  \n",
      " tf.unstack_1 (TFOpLambda)      [(None, 30, 200, 1)  0           ['input_5[0][0]']                \n",
      "                                , (None, 30, 200, 1                                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " model_6 (Functional)           (None, 50)           991790      ['tf.unstack_1[0][0]',           \n",
      "                                                                  'tf.unstack_1[0][1]']           \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 50)           0           ['model_6[0][0]',                \n",
      "                                                                  'model_6[1][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 100)          5100        ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 100)          0           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 50)           5050        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 2)            102         ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,002,042\n",
      "Trainable params: 1,001,802\n",
      "Non-trainable params: 240\n",
      "__________________________________________________________________________________________________\n",
      "开始训练!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "432/432 [==============================] - 15s 27ms/step - loss: 0.2188 - accuracy: 0.6752 - val_loss: 0.1479 - val_accuracy: 0.8108 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.1101 - accuracy: 0.8701 - val_loss: 0.0669 - val_accuracy: 0.9311 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0818 - accuracy: 0.9114 - val_loss: 0.0582 - val_accuracy: 0.9416 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0660 - accuracy: 0.9343 - val_loss: 0.0803 - val_accuracy: 0.9178 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0563 - accuracy: 0.9443 - val_loss: 0.0484 - val_accuracy: 0.9549 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0491 - accuracy: 0.9547 - val_loss: 0.0590 - val_accuracy: 0.9416 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0488 - accuracy: 0.9531 - val_loss: 0.0329 - val_accuracy: 0.9728 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0442 - accuracy: 0.9608 - val_loss: 0.1535 - val_accuracy: 0.8287 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0350 - accuracy: 0.9722 - val_loss: 0.0243 - val_accuracy: 0.9844 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0343 - accuracy: 0.9714 - val_loss: 0.1028 - val_accuracy: 0.8918 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0328 - accuracy: 0.9757 - val_loss: 0.0277 - val_accuracy: 0.9809 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0300 - accuracy: 0.9773 - val_loss: 0.0296 - val_accuracy: 0.9792 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0283 - accuracy: 0.9796 - val_loss: 0.0249 - val_accuracy: 0.9850 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0278 - accuracy: 0.9802 - val_loss: 0.0215 - val_accuracy: 0.9873 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0260 - accuracy: 0.9826 - val_loss: 0.0430 - val_accuracy: 0.9612 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0252 - accuracy: 0.9834 - val_loss: 0.0209 - val_accuracy: 0.9878 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0257 - accuracy: 0.9813 - val_loss: 0.0423 - val_accuracy: 0.9583 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0247 - accuracy: 0.9831 - val_loss: 0.0196 - val_accuracy: 0.9884 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0229 - accuracy: 0.9861 - val_loss: 0.0195 - val_accuracy: 0.9890 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0204 - accuracy: 0.9877 - val_loss: 0.0155 - val_accuracy: 0.9948 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0232 - accuracy: 0.9850 - val_loss: 0.0200 - val_accuracy: 0.9896 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0222 - accuracy: 0.9855 - val_loss: 0.0260 - val_accuracy: 0.9826 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0213 - accuracy: 0.9863 - val_loss: 0.0631 - val_accuracy: 0.9369 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0181 - accuracy: 0.9900 - val_loss: 0.0133 - val_accuracy: 0.9971 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0173 - accuracy: 0.9913 - val_loss: 0.0145 - val_accuracy: 0.9931 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0173 - accuracy: 0.9910 - val_loss: 0.0144 - val_accuracy: 0.9948 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0172 - accuracy: 0.9916 - val_loss: 0.0159 - val_accuracy: 0.9931 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0177 - accuracy: 0.9906 - val_loss: 0.0755 - val_accuracy: 0.9259 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0156 - accuracy: 0.9928 - val_loss: 0.0576 - val_accuracy: 0.9392 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0135 - accuracy: 0.9952 - val_loss: 0.0145 - val_accuracy: 0.9931 - lr: 1.0000e-05\n",
      "Epoch 31/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0127 - accuracy: 0.9962 - val_loss: 0.0125 - val_accuracy: 0.9959 - lr: 1.0000e-05\n",
      "Epoch 32/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0116 - accuracy: 0.9973 - val_loss: 0.0117 - val_accuracy: 0.9983 - lr: 1.0000e-05\n",
      "Epoch 33/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0112 - accuracy: 0.9983 - val_loss: 0.0116 - val_accuracy: 0.9965 - lr: 1.0000e-05\n",
      "Epoch 34/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0113 - accuracy: 0.9981 - val_loss: 0.0119 - val_accuracy: 0.9965 - lr: 1.0000e-05\n",
      "Epoch 35/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0113 - accuracy: 0.9980 - val_loss: 0.0112 - val_accuracy: 0.9977 - lr: 1.0000e-05\n",
      "Epoch 36/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0109 - accuracy: 0.9986 - val_loss: 0.0115 - val_accuracy: 0.9971 - lr: 1.0000e-05\n",
      "Epoch 37/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0110 - accuracy: 0.9983 - val_loss: 0.0110 - val_accuracy: 0.9983 - lr: 1.0000e-05\n",
      "Epoch 38/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0102 - accuracy: 0.9991 - val_loss: 0.0107 - val_accuracy: 0.9983 - lr: 1.0000e-05\n",
      "Epoch 39/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0104 - accuracy: 0.9988 - val_loss: 0.0109 - val_accuracy: 0.9983 - lr: 1.0000e-05\n",
      "Epoch 40/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0104 - accuracy: 0.9990 - val_loss: 0.0115 - val_accuracy: 0.9971 - lr: 1.0000e-05\n",
      "Epoch 41/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0105 - accuracy: 0.9986 - val_loss: 0.0111 - val_accuracy: 0.9983 - lr: 1.0000e-05\n",
      "Epoch 42/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0102 - accuracy: 0.9990 - val_loss: 0.0109 - val_accuracy: 0.9988 - lr: 1.0000e-05\n",
      "Epoch 43/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0104 - accuracy: 0.9987 - val_loss: 0.0110 - val_accuracy: 0.9983 - lr: 1.0000e-05\n",
      "Epoch 44/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0105 - accuracy: 0.9986 - val_loss: 0.0109 - val_accuracy: 0.9983 - lr: 1.0000e-06\n",
      "Epoch 45/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0106 - accuracy: 0.9978 - val_loss: 0.0109 - val_accuracy: 0.9983 - lr: 1.0000e-06\n",
      "Epoch 46/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0106 - accuracy: 0.9977 - val_loss: 0.0109 - val_accuracy: 0.9983 - lr: 1.0000e-06\n",
      "Epoch 47/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0104 - accuracy: 0.9988 - val_loss: 0.0108 - val_accuracy: 0.9983 - lr: 1.0000e-06\n",
      "Epoch 48/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0106 - accuracy: 0.9978 - val_loss: 0.0109 - val_accuracy: 0.9977 - lr: 1.0000e-06\n",
      "(960, 2)\n",
      "(960, 2)\n",
      "$$ 测试集准确率为 accuracy:0.9979166666666667\n",
      "$$ 测试集精确率为 precision:0.9979591836734694\n",
      "$$ 测试集召回率为 recall:0.9978813559322034\n",
      "$$ 测试集f1评分为 f1_score:0.997915933987209\n",
      "fold hao: 3\n",
      "(6911, 2, 30, 200)\n",
      "(6911, 2)\n",
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 2, 30, 200,  0           []                               \n",
      "                                 1)]                                                              \n",
      "                                                                                                  \n",
      " tf.unstack_2 (TFOpLambda)      [(None, 30, 200, 1)  0           ['input_9[0][0]']                \n",
      "                                , (None, 30, 200, 1                                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " model_10 (Functional)          (None, 50)           991790      ['tf.unstack_2[0][0]',           \n",
      "                                                                  'tf.unstack_2[0][1]']           \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 50)           0           ['model_10[0][0]',               \n",
      "                                                                  'model_10[1][0]']               \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 100)          5100        ['add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 100)          0           ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 50)           5050        ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 2)            102         ['dense_13[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,002,042\n",
      "Trainable params: 1,001,802\n",
      "Non-trainable params: 240\n",
      "__________________________________________________________________________________________________\n",
      "开始训练!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "432/432 [==============================] - 16s 27ms/step - loss: 0.2156 - accuracy: 0.6788 - val_loss: 0.1433 - val_accuracy: 0.8183 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.1131 - accuracy: 0.8666 - val_loss: 0.1094 - val_accuracy: 0.8715 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0767 - accuracy: 0.9195 - val_loss: 0.0574 - val_accuracy: 0.9433 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0652 - accuracy: 0.9343 - val_loss: 0.0481 - val_accuracy: 0.9566 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0551 - accuracy: 0.9491 - val_loss: 0.0939 - val_accuracy: 0.9016 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0481 - accuracy: 0.9595 - val_loss: 0.0635 - val_accuracy: 0.9410 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0410 - accuracy: 0.9677 - val_loss: 0.1636 - val_accuracy: 0.8241 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0388 - accuracy: 0.9700 - val_loss: 0.0503 - val_accuracy: 0.9583 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0404 - accuracy: 0.9673 - val_loss: 0.0360 - val_accuracy: 0.9716 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0356 - accuracy: 0.9719 - val_loss: 0.0324 - val_accuracy: 0.9786 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0329 - accuracy: 0.9768 - val_loss: 0.0567 - val_accuracy: 0.9456 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0292 - accuracy: 0.9808 - val_loss: 0.0311 - val_accuracy: 0.9763 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0290 - accuracy: 0.9803 - val_loss: 0.0479 - val_accuracy: 0.9578 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0283 - accuracy: 0.9802 - val_loss: 0.0270 - val_accuracy: 0.9832 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0255 - accuracy: 0.9847 - val_loss: 0.0393 - val_accuracy: 0.9647 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0234 - accuracy: 0.9870 - val_loss: 0.0698 - val_accuracy: 0.9329 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0238 - accuracy: 0.9861 - val_loss: 0.0215 - val_accuracy: 0.9884 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0231 - accuracy: 0.9867 - val_loss: 0.0213 - val_accuracy: 0.9884 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0214 - accuracy: 0.9886 - val_loss: 0.0426 - val_accuracy: 0.9612 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0236 - accuracy: 0.9854 - val_loss: 0.0236 - val_accuracy: 0.9873 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0204 - accuracy: 0.9896 - val_loss: 0.0871 - val_accuracy: 0.9120 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0216 - accuracy: 0.9874 - val_loss: 0.0205 - val_accuracy: 0.9884 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0203 - accuracy: 0.9889 - val_loss: 0.0550 - val_accuracy: 0.9491 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0200 - accuracy: 0.9890 - val_loss: 0.0383 - val_accuracy: 0.9659 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0184 - accuracy: 0.9903 - val_loss: 0.0289 - val_accuracy: 0.9786 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0177 - accuracy: 0.9918 - val_loss: 0.0266 - val_accuracy: 0.9797 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0225 - accuracy: 0.9848 - val_loss: 0.0194 - val_accuracy: 0.9884 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0180 - accuracy: 0.9897 - val_loss: 0.0179 - val_accuracy: 0.9896 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0165 - accuracy: 0.9915 - val_loss: 0.0220 - val_accuracy: 0.9861 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0143 - accuracy: 0.9952 - val_loss: 0.0236 - val_accuracy: 0.9850 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0169 - accuracy: 0.9910 - val_loss: 0.0177 - val_accuracy: 0.9913 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0148 - accuracy: 0.9933 - val_loss: 0.0437 - val_accuracy: 0.9583 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0152 - accuracy: 0.9928 - val_loss: 0.0379 - val_accuracy: 0.9664 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0189 - accuracy: 0.9886 - val_loss: 0.0148 - val_accuracy: 0.9925 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0156 - accuracy: 0.9916 - val_loss: 0.0200 - val_accuracy: 0.9884 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0128 - accuracy: 0.9951 - val_loss: 0.0272 - val_accuracy: 0.9792 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0140 - accuracy: 0.9936 - val_loss: 0.0169 - val_accuracy: 0.9902 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0136 - accuracy: 0.9938 - val_loss: 0.0401 - val_accuracy: 0.9618 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0159 - accuracy: 0.9905 - val_loss: 0.0182 - val_accuracy: 0.9878 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0113 - accuracy: 0.9962 - val_loss: 0.0151 - val_accuracy: 0.9925 - lr: 1.0000e-05\n",
      "Epoch 41/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0105 - accuracy: 0.9978 - val_loss: 0.0145 - val_accuracy: 0.9925 - lr: 1.0000e-05\n",
      "Epoch 42/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0097 - accuracy: 0.9981 - val_loss: 0.0144 - val_accuracy: 0.9925 - lr: 1.0000e-05\n",
      "Epoch 43/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0092 - accuracy: 0.9991 - val_loss: 0.0139 - val_accuracy: 0.9936 - lr: 1.0000e-05\n",
      "Epoch 44/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0091 - accuracy: 0.9996 - val_loss: 0.0139 - val_accuracy: 0.9936 - lr: 1.0000e-05\n",
      "(960, 2)\n",
      "(960, 2)\n",
      "$$ 测试集准确率为 accuracy:0.9947916666666666\n",
      "$$ 测试集精确率为 precision:0.9947851336160314\n",
      "$$ 测试集召回率为 recall:0.9948173484269741\n",
      "$$ 测试集f1评分为 f1_score:0.9947915253777501\n",
      "fold hao: 4\n",
      "(6911, 2, 30, 200)\n",
      "(6911, 2)\n",
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_13 (InputLayer)          [(None, 2, 30, 200,  0           []                               \n",
      "                                 1)]                                                              \n",
      "                                                                                                  \n",
      " tf.unstack_3 (TFOpLambda)      [(None, 30, 200, 1)  0           ['input_13[0][0]']               \n",
      "                                , (None, 30, 200, 1                                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " model_14 (Functional)          (None, 50)           991790      ['tf.unstack_3[0][0]',           \n",
      "                                                                  'tf.unstack_3[0][1]']           \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 50)           0           ['model_14[0][0]',               \n",
      "                                                                  'model_14[1][0]']               \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 100)          5100        ['add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 100)          0           ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 50)           5050        ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 2)            102         ['dense_18[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,002,042\n",
      "Trainable params: 1,001,802\n",
      "Non-trainable params: 240\n",
      "__________________________________________________________________________________________________\n",
      "开始训练!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "432/432 [==============================] - 15s 27ms/step - loss: 0.2272 - accuracy: 0.6471 - val_loss: 0.1238 - val_accuracy: 0.8495 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.1146 - accuracy: 0.8649 - val_loss: 0.0626 - val_accuracy: 0.9381 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0805 - accuracy: 0.9125 - val_loss: 0.0506 - val_accuracy: 0.9554 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0641 - accuracy: 0.9363 - val_loss: 0.1540 - val_accuracy: 0.8241 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0510 - accuracy: 0.9546 - val_loss: 0.2034 - val_accuracy: 0.7760 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0490 - accuracy: 0.9549 - val_loss: 0.0618 - val_accuracy: 0.9381 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0420 - accuracy: 0.9648 - val_loss: 0.0391 - val_accuracy: 0.9664 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0418 - accuracy: 0.9640 - val_loss: 0.0782 - val_accuracy: 0.9138 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0345 - accuracy: 0.9734 - val_loss: 0.0538 - val_accuracy: 0.9485 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0301 - accuracy: 0.9793 - val_loss: 0.1549 - val_accuracy: 0.8339 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0326 - accuracy: 0.9757 - val_loss: 0.0300 - val_accuracy: 0.9786 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0287 - accuracy: 0.9795 - val_loss: 0.0246 - val_accuracy: 0.9867 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0284 - accuracy: 0.9800 - val_loss: 0.0242 - val_accuracy: 0.9855 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0279 - accuracy: 0.9815 - val_loss: 0.0286 - val_accuracy: 0.9797 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0253 - accuracy: 0.9835 - val_loss: 0.0419 - val_accuracy: 0.9612 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0240 - accuracy: 0.9852 - val_loss: 0.0763 - val_accuracy: 0.9213 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0244 - accuracy: 0.9844 - val_loss: 0.0239 - val_accuracy: 0.9855 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0230 - accuracy: 0.9852 - val_loss: 0.0227 - val_accuracy: 0.9844 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0236 - accuracy: 0.9847 - val_loss: 0.0212 - val_accuracy: 0.9884 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0221 - accuracy: 0.9864 - val_loss: 0.0721 - val_accuracy: 0.9265 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0226 - accuracy: 0.9855 - val_loss: 0.0229 - val_accuracy: 0.9844 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0186 - accuracy: 0.9910 - val_loss: 0.0217 - val_accuracy: 0.9873 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0200 - accuracy: 0.9887 - val_loss: 0.0447 - val_accuracy: 0.9578 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0190 - accuracy: 0.9902 - val_loss: 0.0191 - val_accuracy: 0.9902 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0200 - accuracy: 0.9889 - val_loss: 0.0208 - val_accuracy: 0.9873 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0167 - accuracy: 0.9920 - val_loss: 0.0180 - val_accuracy: 0.9896 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0182 - accuracy: 0.9902 - val_loss: 0.0263 - val_accuracy: 0.9803 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0178 - accuracy: 0.9906 - val_loss: 0.0266 - val_accuracy: 0.9797 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0186 - accuracy: 0.9890 - val_loss: 0.0238 - val_accuracy: 0.9821 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0181 - accuracy: 0.9890 - val_loss: 0.0215 - val_accuracy: 0.9844 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0191 - accuracy: 0.9878 - val_loss: 0.0212 - val_accuracy: 0.9855 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0136 - accuracy: 0.9951 - val_loss: 0.0164 - val_accuracy: 0.9913 - lr: 1.0000e-05\n",
      "Epoch 33/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0123 - accuracy: 0.9959 - val_loss: 0.0147 - val_accuracy: 0.9936 - lr: 1.0000e-05\n",
      "Epoch 34/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0120 - accuracy: 0.9975 - val_loss: 0.0142 - val_accuracy: 0.9931 - lr: 1.0000e-05\n",
      "Epoch 35/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0114 - accuracy: 0.9981 - val_loss: 0.0145 - val_accuracy: 0.9936 - lr: 1.0000e-05\n",
      "Epoch 36/100\n",
      "432/432 [==============================] - 11s 24ms/step - loss: 0.0113 - accuracy: 0.9978 - val_loss: 0.0141 - val_accuracy: 0.9931 - lr: 1.0000e-05\n",
      "Epoch 37/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0108 - accuracy: 0.9981 - val_loss: 0.0143 - val_accuracy: 0.9931 - lr: 1.0000e-05\n",
      "Epoch 38/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0105 - accuracy: 0.9991 - val_loss: 0.0140 - val_accuracy: 0.9931 - lr: 1.0000e-05\n",
      "Epoch 39/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0112 - accuracy: 0.9980 - val_loss: 0.0137 - val_accuracy: 0.9948 - lr: 1.0000e-05\n",
      "Epoch 40/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0104 - accuracy: 0.9990 - val_loss: 0.0136 - val_accuracy: 0.9954 - lr: 1.0000e-05\n",
      "Epoch 41/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0104 - accuracy: 0.9986 - val_loss: 0.0139 - val_accuracy: 0.9942 - lr: 1.0000e-05\n",
      "Epoch 42/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0105 - accuracy: 0.9986 - val_loss: 0.0142 - val_accuracy: 0.9936 - lr: 1.0000e-05\n",
      "Epoch 43/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0101 - accuracy: 0.9988 - val_loss: 0.0146 - val_accuracy: 0.9925 - lr: 1.0000e-05\n",
      "Epoch 44/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0100 - accuracy: 0.9991 - val_loss: 0.0152 - val_accuracy: 0.9919 - lr: 1.0000e-05\n",
      "Epoch 45/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0106 - accuracy: 0.9981 - val_loss: 0.0150 - val_accuracy: 0.9919 - lr: 1.0000e-06\n",
      "Epoch 46/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0104 - accuracy: 0.9981 - val_loss: 0.0149 - val_accuracy: 0.9919 - lr: 1.0000e-06\n",
      "Epoch 47/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0106 - accuracy: 0.9981 - val_loss: 0.0151 - val_accuracy: 0.9913 - lr: 1.0000e-06\n",
      "Epoch 48/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0103 - accuracy: 0.9986 - val_loss: 0.0150 - val_accuracy: 0.9919 - lr: 1.0000e-06\n",
      "Epoch 49/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0103 - accuracy: 0.9987 - val_loss: 0.0147 - val_accuracy: 0.9919 - lr: 1.0000e-06\n",
      "(960, 2)\n",
      "(960, 2)\n",
      "$$ 测试集准确率为 accuracy:0.9958333333333333\n",
      "$$ 测试集精确率为 precision:0.9958461919085381\n",
      "$$ 测试集召回率为 recall:0.9958289749521483\n",
      "$$ 测试集f1评分为 f1_score:0.9958332609941145\n",
      "fold hao: 5\n",
      "(6911, 2, 30, 200)\n",
      "(6911, 2)\n",
      "Model: \"model_19\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_17 (InputLayer)          [(None, 2, 30, 200,  0           []                               \n",
      "                                 1)]                                                              \n",
      "                                                                                                  \n",
      " tf.unstack_4 (TFOpLambda)      [(None, 30, 200, 1)  0           ['input_17[0][0]']               \n",
      "                                , (None, 30, 200, 1                                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " model_18 (Functional)          (None, 50)           991790      ['tf.unstack_4[0][0]',           \n",
      "                                                                  'tf.unstack_4[0][1]']           \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 50)           0           ['model_18[0][0]',               \n",
      "                                                                  'model_18[1][0]']               \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 100)          5100        ['add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 100)          0           ['dense_22[0][0]']               \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 50)           5050        ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 2)            102         ['dense_23[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,002,042\n",
      "Trainable params: 1,001,802\n",
      "Non-trainable params: 240\n",
      "__________________________________________________________________________________________________\n",
      "开始训练!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "432/432 [==============================] - 15s 28ms/step - loss: 0.2321 - accuracy: 0.6223 - val_loss: 0.1956 - val_accuracy: 0.7159 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.1144 - accuracy: 0.8689 - val_loss: 0.2023 - val_accuracy: 0.7668 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0817 - accuracy: 0.9123 - val_loss: 0.0981 - val_accuracy: 0.8883 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0641 - accuracy: 0.9360 - val_loss: 0.0463 - val_accuracy: 0.9595 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0546 - accuracy: 0.9462 - val_loss: 0.0711 - val_accuracy: 0.9311 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0489 - accuracy: 0.9554 - val_loss: 0.0414 - val_accuracy: 0.9670 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0488 - accuracy: 0.9559 - val_loss: 0.0715 - val_accuracy: 0.9236 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0410 - accuracy: 0.9657 - val_loss: 0.0405 - val_accuracy: 0.9641 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0385 - accuracy: 0.9676 - val_loss: 0.0518 - val_accuracy: 0.9531 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0353 - accuracy: 0.9714 - val_loss: 0.1580 - val_accuracy: 0.8345 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0312 - accuracy: 0.9776 - val_loss: 0.0360 - val_accuracy: 0.9711 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0326 - accuracy: 0.9740 - val_loss: 0.0281 - val_accuracy: 0.9803 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0298 - accuracy: 0.9790 - val_loss: 0.0592 - val_accuracy: 0.9433 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0282 - accuracy: 0.9796 - val_loss: 0.0567 - val_accuracy: 0.9433 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0288 - accuracy: 0.9786 - val_loss: 0.0337 - val_accuracy: 0.9734 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0243 - accuracy: 0.9848 - val_loss: 0.0219 - val_accuracy: 0.9890 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0268 - accuracy: 0.9822 - val_loss: 0.0275 - val_accuracy: 0.9792 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0248 - accuracy: 0.9825 - val_loss: 0.0406 - val_accuracy: 0.9618 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0219 - accuracy: 0.9871 - val_loss: 0.0223 - val_accuracy: 0.9873 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0217 - accuracy: 0.9868 - val_loss: 0.0406 - val_accuracy: 0.9682 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0247 - accuracy: 0.9845 - val_loss: 0.0205 - val_accuracy: 0.9878 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0209 - accuracy: 0.9876 - val_loss: 0.1047 - val_accuracy: 0.8900 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0232 - accuracy: 0.9832 - val_loss: 0.0261 - val_accuracy: 0.9815 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0183 - accuracy: 0.9903 - val_loss: 0.0216 - val_accuracy: 0.9884 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0220 - accuracy: 0.9855 - val_loss: 0.0269 - val_accuracy: 0.9792 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0170 - accuracy: 0.9922 - val_loss: 0.0331 - val_accuracy: 0.9728 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0153 - accuracy: 0.9942 - val_loss: 0.0189 - val_accuracy: 0.9884 - lr: 1.0000e-05\n",
      "Epoch 28/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0145 - accuracy: 0.9946 - val_loss: 0.0171 - val_accuracy: 0.9907 - lr: 1.0000e-05\n",
      "Epoch 29/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0142 - accuracy: 0.9954 - val_loss: 0.0159 - val_accuracy: 0.9936 - lr: 1.0000e-05\n",
      "Epoch 30/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0123 - accuracy: 0.9974 - val_loss: 0.0161 - val_accuracy: 0.9931 - lr: 1.0000e-05\n",
      "Epoch 31/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0123 - accuracy: 0.9975 - val_loss: 0.0168 - val_accuracy: 0.9919 - lr: 1.0000e-05\n",
      "Epoch 32/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0131 - accuracy: 0.9967 - val_loss: 0.0162 - val_accuracy: 0.9931 - lr: 1.0000e-05\n",
      "Epoch 33/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0114 - accuracy: 0.9986 - val_loss: 0.0170 - val_accuracy: 0.9913 - lr: 1.0000e-05\n",
      "Epoch 34/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0125 - accuracy: 0.9967 - val_loss: 0.0157 - val_accuracy: 0.9919 - lr: 1.0000e-05\n",
      "Epoch 35/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0120 - accuracy: 0.9977 - val_loss: 0.0155 - val_accuracy: 0.9931 - lr: 1.0000e-05\n",
      "Epoch 36/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0119 - accuracy: 0.9980 - val_loss: 0.0157 - val_accuracy: 0.9936 - lr: 1.0000e-05\n",
      "Epoch 37/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0118 - accuracy: 0.9981 - val_loss: 0.0159 - val_accuracy: 0.9931 - lr: 1.0000e-05\n",
      "Epoch 38/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0122 - accuracy: 0.9970 - val_loss: 0.0151 - val_accuracy: 0.9925 - lr: 1.0000e-05\n",
      "Epoch 39/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0121 - accuracy: 0.9971 - val_loss: 0.0163 - val_accuracy: 0.9925 - lr: 1.0000e-05\n",
      "(960, 2)\n",
      "(960, 2)\n",
      "$$ 测试集准确率为 accuracy:0.9927083333333333\n",
      "$$ 测试集精确率为 precision:0.992721976462008\n",
      "$$ 测试集召回率为 recall:0.9926941709642132\n",
      "$$ 测试集f1评分为 f1_score:0.9927069959660572\n",
      "fold hao: 6\n",
      "(6911, 2, 30, 200)\n",
      "(6911, 2)\n",
      "Model: \"model_23\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_21 (InputLayer)          [(None, 2, 30, 200,  0           []                               \n",
      "                                 1)]                                                              \n",
      "                                                                                                  \n",
      " tf.unstack_5 (TFOpLambda)      [(None, 30, 200, 1)  0           ['input_21[0][0]']               \n",
      "                                , (None, 30, 200, 1                                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " model_22 (Functional)          (None, 50)           991790      ['tf.unstack_5[0][0]',           \n",
      "                                                                  'tf.unstack_5[0][1]']           \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, 50)           0           ['model_22[0][0]',               \n",
      "                                                                  'model_22[1][0]']               \n",
      "                                                                                                  \n",
      " dense_27 (Dense)               (None, 100)          5100        ['add_17[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 100)          0           ['dense_27[0][0]']               \n",
      "                                                                                                  \n",
      " dense_28 (Dense)               (None, 50)           5050        ['dropout_11[0][0]']             \n",
      "                                                                                                  \n",
      " dense_29 (Dense)               (None, 2)            102         ['dense_28[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,002,042\n",
      "Trainable params: 1,001,802\n",
      "Non-trainable params: 240\n",
      "__________________________________________________________________________________________________\n",
      "开始训练!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "432/432 [==============================] - 15s 27ms/step - loss: 0.2338 - accuracy: 0.6236 - val_loss: 0.1623 - val_accuracy: 0.7928 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.1226 - accuracy: 0.8517 - val_loss: 0.0967 - val_accuracy: 0.8808 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0830 - accuracy: 0.9088 - val_loss: 0.0792 - val_accuracy: 0.9120 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0666 - accuracy: 0.9275 - val_loss: 0.0422 - val_accuracy: 0.9612 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0550 - accuracy: 0.9456 - val_loss: 0.0431 - val_accuracy: 0.9583 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0460 - accuracy: 0.9570 - val_loss: 0.1026 - val_accuracy: 0.8814 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0416 - accuracy: 0.9624 - val_loss: 0.0676 - val_accuracy: 0.9253 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0363 - accuracy: 0.9696 - val_loss: 0.0317 - val_accuracy: 0.9769 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0371 - accuracy: 0.9683 - val_loss: 0.0384 - val_accuracy: 0.9647 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0355 - accuracy: 0.9709 - val_loss: 0.0533 - val_accuracy: 0.9479 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0318 - accuracy: 0.9737 - val_loss: 0.0400 - val_accuracy: 0.9630 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0295 - accuracy: 0.9774 - val_loss: 0.0504 - val_accuracy: 0.9514 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0279 - accuracy: 0.9782 - val_loss: 0.1589 - val_accuracy: 0.8258 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0224 - accuracy: 0.9852 - val_loss: 0.0183 - val_accuracy: 0.9902 - lr: 1.0000e-05\n",
      "Epoch 15/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0192 - accuracy: 0.9902 - val_loss: 0.0195 - val_accuracy: 0.9896 - lr: 1.0000e-05\n",
      "Epoch 16/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0188 - accuracy: 0.9900 - val_loss: 0.0184 - val_accuracy: 0.9907 - lr: 1.0000e-05\n",
      "Epoch 17/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0181 - accuracy: 0.9913 - val_loss: 0.0181 - val_accuracy: 0.9913 - lr: 1.0000e-05\n",
      "Epoch 18/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0167 - accuracy: 0.9935 - val_loss: 0.0200 - val_accuracy: 0.9902 - lr: 1.0000e-05\n",
      "Epoch 19/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0183 - accuracy: 0.9910 - val_loss: 0.0175 - val_accuracy: 0.9925 - lr: 1.0000e-05\n",
      "Epoch 20/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0173 - accuracy: 0.9923 - val_loss: 0.0185 - val_accuracy: 0.9902 - lr: 1.0000e-05\n",
      "Epoch 21/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0169 - accuracy: 0.9922 - val_loss: 0.0187 - val_accuracy: 0.9907 - lr: 1.0000e-05\n",
      "Epoch 22/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0165 - accuracy: 0.9932 - val_loss: 0.0181 - val_accuracy: 0.9919 - lr: 1.0000e-05\n",
      "Epoch 23/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0157 - accuracy: 0.9941 - val_loss: 0.0189 - val_accuracy: 0.9907 - lr: 1.0000e-05\n",
      "Epoch 24/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0152 - accuracy: 0.9955 - val_loss: 0.0171 - val_accuracy: 0.9936 - lr: 1.0000e-05\n",
      "Epoch 25/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0158 - accuracy: 0.9942 - val_loss: 0.0199 - val_accuracy: 0.9890 - lr: 1.0000e-05\n",
      "Epoch 26/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0155 - accuracy: 0.9941 - val_loss: 0.0174 - val_accuracy: 0.9925 - lr: 1.0000e-05\n",
      "Epoch 27/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0151 - accuracy: 0.9955 - val_loss: 0.0177 - val_accuracy: 0.9919 - lr: 1.0000e-05\n",
      "Epoch 28/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0161 - accuracy: 0.9942 - val_loss: 0.0175 - val_accuracy: 0.9913 - lr: 1.0000e-05\n",
      "Epoch 29/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0142 - accuracy: 0.9968 - val_loss: 0.0177 - val_accuracy: 0.9919 - lr: 1.0000e-05\n",
      "Epoch 30/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0143 - accuracy: 0.9965 - val_loss: 0.0175 - val_accuracy: 0.9931 - lr: 1.0000e-06\n",
      "Epoch 31/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0144 - accuracy: 0.9964 - val_loss: 0.0172 - val_accuracy: 0.9925 - lr: 1.0000e-06\n",
      "Epoch 32/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0143 - accuracy: 0.9961 - val_loss: 0.0171 - val_accuracy: 0.9936 - lr: 1.0000e-06\n",
      "Epoch 33/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0137 - accuracy: 0.9970 - val_loss: 0.0171 - val_accuracy: 0.9931 - lr: 1.0000e-06\n",
      "Epoch 34/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0144 - accuracy: 0.9962 - val_loss: 0.0170 - val_accuracy: 0.9931 - lr: 1.0000e-06\n",
      "(960, 2)\n",
      "(960, 2)\n",
      "$$ 测试集准确率为 accuracy:0.9927083333333333\n",
      "$$ 测试集精确率为 precision:0.9926941709642132\n",
      "$$ 测试集召回率为 recall:0.992721976462008\n",
      "$$ 测试集f1评分为 f1_score:0.9927069959660572\n",
      "fold hao: 7\n",
      "(6911, 2, 30, 200)\n",
      "(6911, 2)\n",
      "Model: \"model_27\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_25 (InputLayer)          [(None, 2, 30, 200,  0           []                               \n",
      "                                 1)]                                                              \n",
      "                                                                                                  \n",
      " tf.unstack_6 (TFOpLambda)      [(None, 30, 200, 1)  0           ['input_25[0][0]']               \n",
      "                                , (None, 30, 200, 1                                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " model_26 (Functional)          (None, 50)           991790      ['tf.unstack_6[0][0]',           \n",
      "                                                                  'tf.unstack_6[0][1]']           \n",
      "                                                                                                  \n",
      " add_20 (Add)                   (None, 50)           0           ['model_26[0][0]',               \n",
      "                                                                  'model_26[1][0]']               \n",
      "                                                                                                  \n",
      " dense_32 (Dense)               (None, 100)          5100        ['add_20[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 100)          0           ['dense_32[0][0]']               \n",
      "                                                                                                  \n",
      " dense_33 (Dense)               (None, 50)           5050        ['dropout_13[0][0]']             \n",
      "                                                                                                  \n",
      " dense_34 (Dense)               (None, 2)            102         ['dense_33[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,002,042\n",
      "Trainable params: 1,001,802\n",
      "Non-trainable params: 240\n",
      "__________________________________________________________________________________________________\n",
      "开始训练!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "432/432 [==============================] - 15s 27ms/step - loss: 0.2233 - accuracy: 0.6636 - val_loss: 0.2491 - val_accuracy: 0.6736 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.1164 - accuracy: 0.8659 - val_loss: 0.2987 - val_accuracy: 0.6522 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0806 - accuracy: 0.9119 - val_loss: 0.1616 - val_accuracy: 0.8166 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0628 - accuracy: 0.9365 - val_loss: 0.0558 - val_accuracy: 0.9444 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0570 - accuracy: 0.9453 - val_loss: 0.1862 - val_accuracy: 0.7888 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0460 - accuracy: 0.9602 - val_loss: 0.1007 - val_accuracy: 0.8912 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0434 - accuracy: 0.9614 - val_loss: 0.0406 - val_accuracy: 0.9682 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0406 - accuracy: 0.9659 - val_loss: 0.0406 - val_accuracy: 0.9659 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0377 - accuracy: 0.9696 - val_loss: 0.0800 - val_accuracy: 0.9178 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0346 - accuracy: 0.9742 - val_loss: 0.1664 - val_accuracy: 0.8142 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0341 - accuracy: 0.9735 - val_loss: 0.0394 - val_accuracy: 0.9676 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0313 - accuracy: 0.9761 - val_loss: 0.0741 - val_accuracy: 0.9265 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0302 - accuracy: 0.9792 - val_loss: 0.0343 - val_accuracy: 0.9734 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0280 - accuracy: 0.9796 - val_loss: 0.0372 - val_accuracy: 0.9722 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0250 - accuracy: 0.9839 - val_loss: 0.0541 - val_accuracy: 0.9491 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0265 - accuracy: 0.9821 - val_loss: 0.0301 - val_accuracy: 0.9780 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0223 - accuracy: 0.9877 - val_loss: 0.0464 - val_accuracy: 0.9589 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0232 - accuracy: 0.9860 - val_loss: 0.0264 - val_accuracy: 0.9826 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0234 - accuracy: 0.9852 - val_loss: 0.0271 - val_accuracy: 0.9815 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0202 - accuracy: 0.9893 - val_loss: 0.0250 - val_accuracy: 0.9838 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0197 - accuracy: 0.9894 - val_loss: 0.0316 - val_accuracy: 0.9763 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0214 - accuracy: 0.9868 - val_loss: 0.0248 - val_accuracy: 0.9832 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0187 - accuracy: 0.9896 - val_loss: 0.0441 - val_accuracy: 0.9606 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0196 - accuracy: 0.9889 - val_loss: 0.0205 - val_accuracy: 0.9878 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0160 - accuracy: 0.9935 - val_loss: 0.0208 - val_accuracy: 0.9873 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0184 - accuracy: 0.9905 - val_loss: 0.0279 - val_accuracy: 0.9774 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0197 - accuracy: 0.9878 - val_loss: 0.2141 - val_accuracy: 0.7784 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0172 - accuracy: 0.9912 - val_loss: 0.0224 - val_accuracy: 0.9838 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0175 - accuracy: 0.9899 - val_loss: 0.1061 - val_accuracy: 0.8947 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0197 - accuracy: 0.9877 - val_loss: 0.0214 - val_accuracy: 0.9867 - lr: 1.0000e-05\n",
      "Epoch 31/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0151 - accuracy: 0.9935 - val_loss: 0.0202 - val_accuracy: 0.9884 - lr: 1.0000e-05\n",
      "Epoch 32/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0129 - accuracy: 0.9959 - val_loss: 0.0187 - val_accuracy: 0.9890 - lr: 1.0000e-05\n",
      "Epoch 33/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0118 - accuracy: 0.9971 - val_loss: 0.0174 - val_accuracy: 0.9907 - lr: 1.0000e-05\n",
      "Epoch 34/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0118 - accuracy: 0.9973 - val_loss: 0.0174 - val_accuracy: 0.9896 - lr: 1.0000e-05\n",
      "Epoch 35/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0119 - accuracy: 0.9977 - val_loss: 0.0167 - val_accuracy: 0.9907 - lr: 1.0000e-05\n",
      "Epoch 36/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0118 - accuracy: 0.9973 - val_loss: 0.0164 - val_accuracy: 0.9913 - lr: 1.0000e-05\n",
      "Epoch 37/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0113 - accuracy: 0.9980 - val_loss: 0.0160 - val_accuracy: 0.9919 - lr: 1.0000e-05\n",
      "Epoch 38/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0113 - accuracy: 0.9981 - val_loss: 0.0164 - val_accuracy: 0.9902 - lr: 1.0000e-05\n",
      "Epoch 39/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0103 - accuracy: 0.9993 - val_loss: 0.0173 - val_accuracy: 0.9902 - lr: 1.0000e-05\n",
      "Epoch 40/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0116 - accuracy: 0.9974 - val_loss: 0.0178 - val_accuracy: 0.9902 - lr: 1.0000e-05\n",
      "Epoch 41/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0111 - accuracy: 0.9980 - val_loss: 0.0162 - val_accuracy: 0.9913 - lr: 1.0000e-05\n",
      "Epoch 42/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0107 - accuracy: 0.9984 - val_loss: 0.0165 - val_accuracy: 0.9907 - lr: 1.0000e-05\n",
      "Epoch 43/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0103 - accuracy: 0.9991 - val_loss: 0.0157 - val_accuracy: 0.9919 - lr: 1.0000e-06\n",
      "Epoch 44/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0107 - accuracy: 0.9984 - val_loss: 0.0158 - val_accuracy: 0.9913 - lr: 1.0000e-06\n",
      "Epoch 45/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0104 - accuracy: 0.9988 - val_loss: 0.0156 - val_accuracy: 0.9913 - lr: 1.0000e-06\n",
      "Epoch 46/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0105 - accuracy: 0.9988 - val_loss: 0.0157 - val_accuracy: 0.9913 - lr: 1.0000e-06\n",
      "(960, 2)\n",
      "(960, 2)\n",
      "$$ 测试集准确率为 accuracy:0.996875\n",
      "$$ 测试集精确率为 precision:0.9968085106382979\n",
      "$$ 测试集召回率为 recall:0.9969574036511156\n",
      "$$ 测试集f1评分为 f1_score:0.9968732052143645\n",
      "fold hao: 8\n",
      "(6911, 2, 30, 200)\n",
      "(6911, 2)\n",
      "Model: \"model_31\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_29 (InputLayer)          [(None, 2, 30, 200,  0           []                               \n",
      "                                 1)]                                                              \n",
      "                                                                                                  \n",
      " tf.unstack_7 (TFOpLambda)      [(None, 30, 200, 1)  0           ['input_29[0][0]']               \n",
      "                                , (None, 30, 200, 1                                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " model_30 (Functional)          (None, 50)           991790      ['tf.unstack_7[0][0]',           \n",
      "                                                                  'tf.unstack_7[0][1]']           \n",
      "                                                                                                  \n",
      " add_23 (Add)                   (None, 50)           0           ['model_30[0][0]',               \n",
      "                                                                  'model_30[1][0]']               \n",
      "                                                                                                  \n",
      " dense_37 (Dense)               (None, 100)          5100        ['add_23[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 100)          0           ['dense_37[0][0]']               \n",
      "                                                                                                  \n",
      " dense_38 (Dense)               (None, 50)           5050        ['dropout_15[0][0]']             \n",
      "                                                                                                  \n",
      " dense_39 (Dense)               (None, 2)            102         ['dense_38[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,002,042\n",
      "Trainable params: 1,001,802\n",
      "Non-trainable params: 240\n",
      "__________________________________________________________________________________________________\n",
      "开始训练!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "432/432 [==============================] - 15s 27ms/step - loss: 0.2174 - accuracy: 0.6694 - val_loss: 0.1266 - val_accuracy: 0.8443 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.1210 - accuracy: 0.8563 - val_loss: 0.1039 - val_accuracy: 0.8802 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0864 - accuracy: 0.9067 - val_loss: 0.1437 - val_accuracy: 0.8356 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0695 - accuracy: 0.9314 - val_loss: 0.1158 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0596 - accuracy: 0.9431 - val_loss: 0.1194 - val_accuracy: 0.8559 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0511 - accuracy: 0.9533 - val_loss: 0.0383 - val_accuracy: 0.9676 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0447 - accuracy: 0.9605 - val_loss: 0.3317 - val_accuracy: 0.6464 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0409 - accuracy: 0.9654 - val_loss: 0.0463 - val_accuracy: 0.9583 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0380 - accuracy: 0.9673 - val_loss: 0.0980 - val_accuracy: 0.8929 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0323 - accuracy: 0.9755 - val_loss: 0.0302 - val_accuracy: 0.9815 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0296 - accuracy: 0.9783 - val_loss: 0.0269 - val_accuracy: 0.9832 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0284 - accuracy: 0.9802 - val_loss: 0.0380 - val_accuracy: 0.9641 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0280 - accuracy: 0.9810 - val_loss: 0.0253 - val_accuracy: 0.9838 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0274 - accuracy: 0.9813 - val_loss: 0.0239 - val_accuracy: 0.9861 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0238 - accuracy: 0.9855 - val_loss: 0.0244 - val_accuracy: 0.9855 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0247 - accuracy: 0.9842 - val_loss: 0.0698 - val_accuracy: 0.9311 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0246 - accuracy: 0.9831 - val_loss: 0.1101 - val_accuracy: 0.8854 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0215 - accuracy: 0.9867 - val_loss: 0.0316 - val_accuracy: 0.9751 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0218 - accuracy: 0.9865 - val_loss: 0.0210 - val_accuracy: 0.9878 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0218 - accuracy: 0.9868 - val_loss: 0.0523 - val_accuracy: 0.9514 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0224 - accuracy: 0.9863 - val_loss: 0.0209 - val_accuracy: 0.9867 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0220 - accuracy: 0.9852 - val_loss: 0.0363 - val_accuracy: 0.9676 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0182 - accuracy: 0.9905 - val_loss: 0.0187 - val_accuracy: 0.9890 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0159 - accuracy: 0.9933 - val_loss: 0.0262 - val_accuracy: 0.9803 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0180 - accuracy: 0.9905 - val_loss: 0.0729 - val_accuracy: 0.9253 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0176 - accuracy: 0.9903 - val_loss: 0.0242 - val_accuracy: 0.9838 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0168 - accuracy: 0.9907 - val_loss: 0.0168 - val_accuracy: 0.9907 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0159 - accuracy: 0.9915 - val_loss: 0.0391 - val_accuracy: 0.9647 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0192 - accuracy: 0.9881 - val_loss: 0.0950 - val_accuracy: 0.8970 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0180 - accuracy: 0.9893 - val_loss: 0.0176 - val_accuracy: 0.9896 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0144 - accuracy: 0.9931 - val_loss: 0.0161 - val_accuracy: 0.9919 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0140 - accuracy: 0.9939 - val_loss: 0.0164 - val_accuracy: 0.9907 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0135 - accuracy: 0.9944 - val_loss: 0.0287 - val_accuracy: 0.9763 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0158 - accuracy: 0.9912 - val_loss: 0.0171 - val_accuracy: 0.9907 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0150 - accuracy: 0.9919 - val_loss: 0.0584 - val_accuracy: 0.9387 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0177 - accuracy: 0.9878 - val_loss: 0.0187 - val_accuracy: 0.9861 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0126 - accuracy: 0.9948 - val_loss: 0.0141 - val_accuracy: 0.9925 - lr: 1.0000e-05\n",
      "Epoch 38/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0106 - accuracy: 0.9970 - val_loss: 0.0134 - val_accuracy: 0.9942 - lr: 1.0000e-05\n",
      "Epoch 39/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0098 - accuracy: 0.9984 - val_loss: 0.0134 - val_accuracy: 0.9942 - lr: 1.0000e-05\n",
      "Epoch 40/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0111 - accuracy: 0.9967 - val_loss: 0.0123 - val_accuracy: 0.9954 - lr: 1.0000e-05\n",
      "Epoch 41/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0097 - accuracy: 0.9981 - val_loss: 0.0125 - val_accuracy: 0.9942 - lr: 1.0000e-05\n",
      "Epoch 42/100\n",
      "432/432 [==============================] - 11s 25ms/step - loss: 0.0105 - accuracy: 0.9975 - val_loss: 0.0125 - val_accuracy: 0.9948 - lr: 1.0000e-05\n",
      "Epoch 43/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0102 - accuracy: 0.9973 - val_loss: 0.0124 - val_accuracy: 0.9954 - lr: 1.0000e-05\n",
      "Epoch 44/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0098 - accuracy: 0.9977 - val_loss: 0.0129 - val_accuracy: 0.9936 - lr: 1.0000e-05\n",
      "Epoch 45/100\n",
      "432/432 [==============================] - 11s 27ms/step - loss: 0.0097 - accuracy: 0.9983 - val_loss: 0.0126 - val_accuracy: 0.9942 - lr: 1.0000e-05\n",
      "Epoch 46/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0095 - accuracy: 0.9984 - val_loss: 0.0129 - val_accuracy: 0.9948 - lr: 1.0000e-06\n",
      "Epoch 47/100\n",
      "432/432 [==============================] - 12s 27ms/step - loss: 0.0096 - accuracy: 0.9981 - val_loss: 0.0127 - val_accuracy: 0.9942 - lr: 1.0000e-06\n",
      "Epoch 48/100\n",
      "432/432 [==============================] - 12s 27ms/step - loss: 0.0094 - accuracy: 0.9983 - val_loss: 0.0128 - val_accuracy: 0.9948 - lr: 1.0000e-06\n",
      "Epoch 49/100\n",
      "432/432 [==============================] - 12s 28ms/step - loss: 0.0096 - accuracy: 0.9981 - val_loss: 0.0126 - val_accuracy: 0.9948 - lr: 1.0000e-06\n",
      "Epoch 50/100\n",
      "432/432 [==============================] - 12s 27ms/step - loss: 0.0092 - accuracy: 0.9987 - val_loss: 0.0122 - val_accuracy: 0.9948 - lr: 1.0000e-06\n",
      "(960, 2)\n",
      "(960, 2)\n",
      "$$ 测试集准确率为 accuracy:0.9947916666666666\n",
      "$$ 测试集精确率为 precision:0.9947296527182636\n",
      "$$ 测试集召回率为 recall:0.9948308270676691\n",
      "$$ 测试集f1评分为 f1_score:0.9947791527217473\n",
      "fold hao: 9\n",
      "(6911, 2, 30, 200)\n",
      "(6911, 2)\n",
      "Model: \"model_35\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_33 (InputLayer)          [(None, 2, 30, 200,  0           []                               \n",
      "                                 1)]                                                              \n",
      "                                                                                                  \n",
      " tf.unstack_8 (TFOpLambda)      [(None, 30, 200, 1)  0           ['input_33[0][0]']               \n",
      "                                , (None, 30, 200, 1                                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " model_34 (Functional)          (None, 50)           991790      ['tf.unstack_8[0][0]',           \n",
      "                                                                  'tf.unstack_8[0][1]']           \n",
      "                                                                                                  \n",
      " add_26 (Add)                   (None, 50)           0           ['model_34[0][0]',               \n",
      "                                                                  'model_34[1][0]']               \n",
      "                                                                                                  \n",
      " dense_42 (Dense)               (None, 100)          5100        ['add_26[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 100)          0           ['dense_42[0][0]']               \n",
      "                                                                                                  \n",
      " dense_43 (Dense)               (None, 50)           5050        ['dropout_17[0][0]']             \n",
      "                                                                                                  \n",
      " dense_44 (Dense)               (None, 2)            102         ['dense_43[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,002,042\n",
      "Trainable params: 1,001,802\n",
      "Non-trainable params: 240\n",
      "__________________________________________________________________________________________________\n",
      "开始训练!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "432/432 [==============================] - 16s 28ms/step - loss: 0.2253 - accuracy: 0.6532 - val_loss: 0.1620 - val_accuracy: 0.7870 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.1157 - accuracy: 0.8659 - val_loss: 0.0635 - val_accuracy: 0.9387 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "432/432 [==============================] - 12s 28ms/step - loss: 0.0775 - accuracy: 0.9177 - val_loss: 0.0769 - val_accuracy: 0.9213 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "432/432 [==============================] - 11s 27ms/step - loss: 0.0644 - accuracy: 0.9365 - val_loss: 0.0572 - val_accuracy: 0.9450 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "432/432 [==============================] - 12s 27ms/step - loss: 0.0555 - accuracy: 0.9491 - val_loss: 0.0590 - val_accuracy: 0.9439 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "432/432 [==============================] - 12s 27ms/step - loss: 0.0516 - accuracy: 0.9512 - val_loss: 0.0539 - val_accuracy: 0.9485 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "432/432 [==============================] - 12s 27ms/step - loss: 0.0446 - accuracy: 0.9619 - val_loss: 0.0378 - val_accuracy: 0.9659 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "432/432 [==============================] - 12s 28ms/step - loss: 0.0396 - accuracy: 0.9683 - val_loss: 0.0322 - val_accuracy: 0.9751 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "432/432 [==============================] - 12s 28ms/step - loss: 0.0372 - accuracy: 0.9699 - val_loss: 0.0842 - val_accuracy: 0.9057 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "432/432 [==============================] - 12s 29ms/step - loss: 0.0367 - accuracy: 0.9702 - val_loss: 0.1138 - val_accuracy: 0.8738 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "432/432 [==============================] - 12s 28ms/step - loss: 0.0319 - accuracy: 0.9784 - val_loss: 0.0368 - val_accuracy: 0.9699 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "432/432 [==============================] - 12s 27ms/step - loss: 0.0275 - accuracy: 0.9825 - val_loss: 0.0669 - val_accuracy: 0.9340 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0307 - accuracy: 0.9767 - val_loss: 0.0474 - val_accuracy: 0.9583 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0227 - accuracy: 0.9877 - val_loss: 0.0222 - val_accuracy: 0.9884 - lr: 1.0000e-05\n",
      "Epoch 15/100\n",
      "432/432 [==============================] - 12s 27ms/step - loss: 0.0194 - accuracy: 0.9928 - val_loss: 0.0217 - val_accuracy: 0.9896 - lr: 1.0000e-05\n",
      "Epoch 16/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0190 - accuracy: 0.9928 - val_loss: 0.0213 - val_accuracy: 0.9902 - lr: 1.0000e-05\n",
      "Epoch 17/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0189 - accuracy: 0.9920 - val_loss: 0.0227 - val_accuracy: 0.9878 - lr: 1.0000e-05\n",
      "Epoch 18/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0184 - accuracy: 0.9932 - val_loss: 0.0207 - val_accuracy: 0.9907 - lr: 1.0000e-05\n",
      "Epoch 19/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0180 - accuracy: 0.9935 - val_loss: 0.0193 - val_accuracy: 0.9925 - lr: 1.0000e-05\n",
      "Epoch 20/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0180 - accuracy: 0.9939 - val_loss: 0.0197 - val_accuracy: 0.9913 - lr: 1.0000e-05\n",
      "Epoch 21/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0165 - accuracy: 0.9955 - val_loss: 0.0203 - val_accuracy: 0.9913 - lr: 1.0000e-05\n",
      "Epoch 22/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0161 - accuracy: 0.9961 - val_loss: 0.0197 - val_accuracy: 0.9919 - lr: 1.0000e-05\n",
      "Epoch 23/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0178 - accuracy: 0.9939 - val_loss: 0.0238 - val_accuracy: 0.9861 - lr: 1.0000e-05\n",
      "Epoch 24/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0166 - accuracy: 0.9957 - val_loss: 0.0178 - val_accuracy: 0.9942 - lr: 1.0000e-05\n",
      "Epoch 25/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0176 - accuracy: 0.9939 - val_loss: 0.0181 - val_accuracy: 0.9931 - lr: 1.0000e-05\n",
      "Epoch 26/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0165 - accuracy: 0.9952 - val_loss: 0.0194 - val_accuracy: 0.9919 - lr: 1.0000e-05\n",
      "Epoch 27/100\n",
      "432/432 [==============================] - 12s 28ms/step - loss: 0.0168 - accuracy: 0.9944 - val_loss: 0.0206 - val_accuracy: 0.9902 - lr: 1.0000e-05\n",
      "Epoch 28/100\n",
      "432/432 [==============================] - 12s 28ms/step - loss: 0.0159 - accuracy: 0.9959 - val_loss: 0.0191 - val_accuracy: 0.9925 - lr: 1.0000e-05\n",
      "Epoch 29/100\n",
      "432/432 [==============================] - 12s 27ms/step - loss: 0.0153 - accuracy: 0.9970 - val_loss: 0.0200 - val_accuracy: 0.9902 - lr: 1.0000e-05\n",
      "Epoch 30/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0161 - accuracy: 0.9957 - val_loss: 0.0189 - val_accuracy: 0.9913 - lr: 1.0000e-06\n",
      "Epoch 31/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0163 - accuracy: 0.9949 - val_loss: 0.0189 - val_accuracy: 0.9913 - lr: 1.0000e-06\n",
      "Epoch 32/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0150 - accuracy: 0.9974 - val_loss: 0.0198 - val_accuracy: 0.9907 - lr: 1.0000e-06\n",
      "Epoch 33/100\n",
      "432/432 [==============================] - 12s 27ms/step - loss: 0.0149 - accuracy: 0.9975 - val_loss: 0.0195 - val_accuracy: 0.9913 - lr: 1.0000e-06\n",
      "Epoch 34/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0149 - accuracy: 0.9973 - val_loss: 0.0198 - val_accuracy: 0.9902 - lr: 1.0000e-06\n",
      "(960, 2)\n",
      "(960, 2)\n",
      "$$ 测试集准确率为 accuracy:0.996875\n",
      "$$ 测试集精确率为 precision:0.996842105263158\n",
      "$$ 测试集召回率为 recall:0.9969262295081966\n",
      "$$ 测试集f1评分为 f1_score:0.996874426842596\n",
      "fold hao: 10\n",
      "(6912, 2, 30, 200)\n",
      "(6912, 2)\n",
      "Model: \"model_39\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_37 (InputLayer)          [(None, 2, 30, 200,  0           []                               \n",
      "                                 1)]                                                              \n",
      "                                                                                                  \n",
      " tf.unstack_9 (TFOpLambda)      [(None, 30, 200, 1)  0           ['input_37[0][0]']               \n",
      "                                , (None, 30, 200, 1                                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " model_38 (Functional)          (None, 50)           991790      ['tf.unstack_9[0][0]',           \n",
      "                                                                  'tf.unstack_9[0][1]']           \n",
      "                                                                                                  \n",
      " add_29 (Add)                   (None, 50)           0           ['model_38[0][0]',               \n",
      "                                                                  'model_38[1][0]']               \n",
      "                                                                                                  \n",
      " dense_47 (Dense)               (None, 100)          5100        ['add_29[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)           (None, 100)          0           ['dense_47[0][0]']               \n",
      "                                                                                                  \n",
      " dense_48 (Dense)               (None, 50)           5050        ['dropout_19[0][0]']             \n",
      "                                                                                                  \n",
      " dense_49 (Dense)               (None, 2)            102         ['dense_48[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,002,042\n",
      "Trainable params: 1,001,802\n",
      "Non-trainable params: 240\n",
      "__________________________________________________________________________________________________\n",
      "开始训练!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "432/432 [==============================] - 16s 28ms/step - loss: 0.2230 - accuracy: 0.6599 - val_loss: 0.1312 - val_accuracy: 0.8362 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.1164 - accuracy: 0.8621 - val_loss: 0.0730 - val_accuracy: 0.9230 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0803 - accuracy: 0.9129 - val_loss: 0.0539 - val_accuracy: 0.9543 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "432/432 [==============================] - 12s 27ms/step - loss: 0.0617 - accuracy: 0.9372 - val_loss: 0.0433 - val_accuracy: 0.9612 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "432/432 [==============================] - 13s 30ms/step - loss: 0.0546 - accuracy: 0.9478 - val_loss: 0.0386 - val_accuracy: 0.9676 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "432/432 [==============================] - 13s 29ms/step - loss: 0.0452 - accuracy: 0.9609 - val_loss: 0.0337 - val_accuracy: 0.9757 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "432/432 [==============================] - 12s 27ms/step - loss: 0.0427 - accuracy: 0.9624 - val_loss: 0.0331 - val_accuracy: 0.9757 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "432/432 [==============================] - 13s 30ms/step - loss: 0.0345 - accuracy: 0.9722 - val_loss: 0.0683 - val_accuracy: 0.9288 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "432/432 [==============================] - 13s 29ms/step - loss: 0.0324 - accuracy: 0.9747 - val_loss: 0.0961 - val_accuracy: 0.8964 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "432/432 [==============================] - 13s 31ms/step - loss: 0.0343 - accuracy: 0.9722 - val_loss: 0.0272 - val_accuracy: 0.9826 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "432/432 [==============================] - 12s 29ms/step - loss: 0.0325 - accuracy: 0.9742 - val_loss: 0.0246 - val_accuracy: 0.9855 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "432/432 [==============================] - 13s 31ms/step - loss: 0.0278 - accuracy: 0.9805 - val_loss: 0.2259 - val_accuracy: 0.7535 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "432/432 [==============================] - 13s 31ms/step - loss: 0.0274 - accuracy: 0.9812 - val_loss: 0.0620 - val_accuracy: 0.9381 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "432/432 [==============================] - 13s 31ms/step - loss: 0.0280 - accuracy: 0.9795 - val_loss: 0.0239 - val_accuracy: 0.9850 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "432/432 [==============================] - 12s 27ms/step - loss: 0.0237 - accuracy: 0.9852 - val_loss: 0.0789 - val_accuracy: 0.9196 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "432/432 [==============================] - 12s 27ms/step - loss: 0.0259 - accuracy: 0.9831 - val_loss: 0.0341 - val_accuracy: 0.9734 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "432/432 [==============================] - 13s 29ms/step - loss: 0.0249 - accuracy: 0.9825 - val_loss: 0.0884 - val_accuracy: 0.9120 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "432/432 [==============================] - 13s 31ms/step - loss: 0.0257 - accuracy: 0.9826 - val_loss: 0.0226 - val_accuracy: 0.9844 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "432/432 [==============================] - 13s 30ms/step - loss: 0.0223 - accuracy: 0.9861 - val_loss: 0.0795 - val_accuracy: 0.9178 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "432/432 [==============================] - 12s 29ms/step - loss: 0.0204 - accuracy: 0.9883 - val_loss: 0.0229 - val_accuracy: 0.9861 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "432/432 [==============================] - 13s 29ms/step - loss: 0.0185 - accuracy: 0.9902 - val_loss: 0.0261 - val_accuracy: 0.9792 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "432/432 [==============================] - 12s 27ms/step - loss: 0.0232 - accuracy: 0.9838 - val_loss: 0.0488 - val_accuracy: 0.9514 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0193 - accuracy: 0.9891 - val_loss: 0.0238 - val_accuracy: 0.9850 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0174 - accuracy: 0.9913 - val_loss: 0.0193 - val_accuracy: 0.9890 - lr: 1.0000e-05\n",
      "Epoch 25/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0146 - accuracy: 0.9948 - val_loss: 0.0177 - val_accuracy: 0.9907 - lr: 1.0000e-05\n",
      "Epoch 26/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0140 - accuracy: 0.9949 - val_loss: 0.0169 - val_accuracy: 0.9925 - lr: 1.0000e-05\n",
      "Epoch 27/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.0159 - val_accuracy: 0.9936 - lr: 1.0000e-05\n",
      "Epoch 28/100\n",
      "432/432 [==============================] - 12s 28ms/step - loss: 0.0133 - accuracy: 0.9962 - val_loss: 0.0158 - val_accuracy: 0.9942 - lr: 1.0000e-05\n",
      "Epoch 29/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0125 - accuracy: 0.9974 - val_loss: 0.0156 - val_accuracy: 0.9942 - lr: 1.0000e-05\n",
      "Epoch 30/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0132 - accuracy: 0.9968 - val_loss: 0.0169 - val_accuracy: 0.9919 - lr: 1.0000e-05\n",
      "Epoch 31/100\n",
      "432/432 [==============================] - 12s 27ms/step - loss: 0.0126 - accuracy: 0.9973 - val_loss: 0.0152 - val_accuracy: 0.9942 - lr: 1.0000e-05\n",
      "Epoch 32/100\n",
      "432/432 [==============================] - 13s 30ms/step - loss: 0.0125 - accuracy: 0.9968 - val_loss: 0.0158 - val_accuracy: 0.9936 - lr: 1.0000e-05\n",
      "Epoch 33/100\n",
      "432/432 [==============================] - 12s 28ms/step - loss: 0.0123 - accuracy: 0.9973 - val_loss: 0.0152 - val_accuracy: 0.9954 - lr: 1.0000e-05\n",
      "Epoch 34/100\n",
      "432/432 [==============================] - 11s 27ms/step - loss: 0.0119 - accuracy: 0.9978 - val_loss: 0.0166 - val_accuracy: 0.9913 - lr: 1.0000e-05\n",
      "Epoch 35/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0115 - accuracy: 0.9986 - val_loss: 0.0149 - val_accuracy: 0.9948 - lr: 1.0000e-05\n",
      "Epoch 36/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0120 - accuracy: 0.9974 - val_loss: 0.0153 - val_accuracy: 0.9931 - lr: 1.0000e-05\n",
      "Epoch 37/100\n",
      "432/432 [==============================] - 11s 26ms/step - loss: 0.0115 - accuracy: 0.9981 - val_loss: 0.0157 - val_accuracy: 0.9925 - lr: 1.0000e-05\n",
      "(959, 2)\n",
      "(959, 2)\n",
      "$$ 测试集准确率为 accuracy:0.9947862356621481\n",
      "$$ 测试集精确率为 precision:0.994799415342051\n",
      "$$ 测试集召回率为 recall:0.9947735873678716\n",
      "$$ 测试集f1评分为 f1_score:0.9947854191837848\n",
      "$$ 测试集准确率为 accuracy:0.9947911235662149\n",
      "$$ 测试集精确率为 precision:0.9947791442347818\n",
      "$$ 测试集召回率为 recall:0.9948094477864201\n",
      "$$ 测试集f1评分为 f1_score:0.9947891092206647\n"
     ]
    }
   ],
   "source": [
    "# 创建十折交叉验证中显示第几折的指示变量\n",
    "ind_fold=0\n",
    "# 进行十折交叉验证\n",
    "for train_ind,test_ind in kfold.split(data_all,label_all):\n",
    "    # 显示训练到第几折\n",
    "    ind_fold=ind_fold+1\n",
    "    print('fold hao:',ind_fold)\n",
    "    # 每一折验证前都要打乱训练集样本顺序\n",
    "    n=len(train_ind)\n",
    "    A=np.linspace(0,n-1,n,dtype=int)\n",
    "    random.shuffle(A)\n",
    "    # 构建训练集、验证集、测试集\n",
    "    epoch_train=data_all[train_ind[A[:int(0.8*n)]]]\n",
    "    epoch_val=data_all[train_ind[A[int(0.8*n):]]]\n",
    "    epoch_test=data_all[test_ind]\n",
    "    label_train=label_all[train_ind[A[:int(0.8*n)]]]\n",
    "    label_val=label_all[train_ind[A[int(0.8*n):]]]\n",
    "    label_test=label_all[test_ind]\n",
    "\n",
    "    print(epoch_train.shape)\n",
    "    print(label_train.shape)\n",
    "    \n",
    "    db_train=tf.data.Dataset.from_tensor_slices((epoch_train,label_train))\n",
    "    db_val=tf.data.Dataset.from_tensor_slices((epoch_val,label_val))\n",
    "    db_train=db_train.shuffle(1000).batch(batchsz)\n",
    "    db_val=db_val.shuffle(1000).batch(batchsz)\n",
    "\n",
    "    # 选择、创建模型\n",
    "    model=mymodel(nb_classes=2,dropoutRate=0.3)  \n",
    "    # 显示模型结构\n",
    "    model.summary()\n",
    "    # 创建Early Stopping类，连续3次不下降则终止\n",
    "    early_stopping = EarlyStopping(monitor='val_loss',min_delta=0.001,patience=10)\n",
    "    reduce_lr=keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",patience=5)\n",
    "    # 配置模型训练\n",
    "    model.compile(optimizer=optimizers.Adam(lr=1e-4),\n",
    "                   loss=losses.MSE,\n",
    "                   metrics=['accuracy'])\n",
    "    # 开始训练模型\n",
    "    print('开始训练!!') \n",
    "    history=model.fit(db_train, validation_data=db_val, validation_freq=1,  \n",
    "                         shuffle=True, epochs=100,callbacks=[early_stopping,reduce_lr])\n",
    "    # 提取和保存训练记录\n",
    "    history = history.history\n",
    "    historys.append(history)\n",
    "    # # 计算、保存测试结果\n",
    "    pred_test=model.predict(epoch_test)\n",
    "    pred_test=np.rint(pred_test)\n",
    "    print(pred_test.shape)\n",
    "    print(label_test.shape)\n",
    "    # 保存测试集预测结果和真实结果\n",
    "    test_pred.append(pred_test)\n",
    "    test_real.append(label_test)\n",
    "    # 计算准确率，精确率，召回率，f1评分\n",
    "    acc=accuracy_score(pred_test,label_test)\n",
    "    pre=precision_score(pred_test,label_test,average='macro')\n",
    "    rec=recall_score(pred_test,label_test,average='macro')\n",
    "    f1=f1_score(pred_test,label_test,average='macro')\n",
    "    accuracy.append(acc)\n",
    "    precision.append(pre)\n",
    "    recall.append(rec)\n",
    "    f1score.append(f1)\n",
    "    print(f\"$$ 测试集准确率为 accuracy:{acc}\")\n",
    "    print(f\"$$ 测试集精确率为 precision:{pre}\")\n",
    "    print(f\"$$ 测试集召回率为 recall:{rec}\")\n",
    "    print(f\"$$ 测试集f1评分为 f1_score:{f1}\")\n",
    "# 将每一折history中误差结果保存（训练集和测试集，用于反映训练过程）    \n",
    "loss_train=[]\n",
    "loss_val=[]\n",
    "for history_s in historys:\n",
    "    loss_val.append(history_s['val_loss'])\n",
    "    loss_train.append(history_s['loss'])\n",
    "\n",
    "print(f\"$$ 测试集准确率为 accuracy:{np.mean(accuracy)}\")\n",
    "print(f\"$$ 测试集精确率为 precision:{np.mean(precision)}\")\n",
    "print(f\"$$ 测试集召回率为 recall:{np.mean(recall)}\")\n",
    "print(f\"$$ 测试集f1评分为 f1_score:{np.mean(f1score)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tens",
   "language": "python",
   "name": "kernelname"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
